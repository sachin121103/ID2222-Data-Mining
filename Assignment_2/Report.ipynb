{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42a112fd-9a11-4d38-bd95-6d85d6573674",
   "metadata": {},
   "source": [
    "# Assignment 2 - Discovery of Frequent Itemsets and Association Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6170d30-bc61-4b41-8f51-989747e2e882",
   "metadata": {},
   "source": [
    "## By Sachin Prabhu Ram and Anirudh Tiwari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106c8b0-d7c7-49b5-92dc-1ba825120a60",
   "metadata": {},
   "source": [
    "In this report, we will go through the method of discovering frequent itemsets and the association rules between them. The problem that we approaching is that of frequent itemsets in a basket of transactions. We do this by defining two integral terms: Support (s) and Confidence (c). **Support** measures how frequently an item X occurs in the dataset; it is calculated as the number of transactions containing X divided by the total number of transactions. **Confidence** rules between two items X and Y measures the fraction of baskets with of all of X containing Y. Using these metrics, we can also find the **Interest** of an association rule, which is the confidence - support.\n",
    "\n",
    "Some terms constantly used are singletons, doubletons and tripletons, commonly known as k-itemsets, where k is an integer that represents the length of the set. Singletons contain one element in a basket, doubletons, two and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9846cbd4-3e35-46a3-a78c-3f70dc7966ab",
   "metadata": {},
   "source": [
    "This specific dataset (T10I4D100K.dat) contains a list of 100,000 transactions, each with varying lengths and items, where each item is represented by a number. The technology stack used is Python without any framework. We only utilise libraries such as collections and itertools. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed87d4c-f748-4c49-8dbf-8bd00e0487a3",
   "metadata": {},
   "source": [
    "### Data Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af5ffd7-19a9-481d-9e68-a44331b376ba",
   "metadata": {},
   "source": [
    "To read in the content of the file, we use the data_parser function below. The sole parameter of the function is the name of the data file, which will be passed as a string. We initialise an empty list that is used to store the sets. We then read every line in the file, format the line for processing and add each line into its own individual set. The list of sets is then returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f2198d-9778-4689-8a48-f0149a471dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_parser(data_file):\n",
    "    set_list = []\n",
    "    with open(data_file, 'r') as df:\n",
    "        for line in df:\n",
    "            line = line.strip().split()\n",
    "            individual_set = set(int(x) for x in line)\n",
    "            set_list.append(individual_set)\n",
    "\n",
    "    return set_list\n",
    "\n",
    "\n",
    "data_file = \"T10I4D100K.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f306221-3825-4619-85cd-edf22fa7fbc1",
   "metadata": {},
   "source": [
    "### A-Priori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2690d5-930d-45e3-beb6-c1695a4359a2",
   "metadata": {},
   "source": [
    "There are two functions below: One to get the frequent singletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16c8dd13-10a2-4785-a0ab-1045fc108c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_singletons(data, s):\n",
    "    all_items = []\n",
    "    for d in data:\n",
    "        for item in d:\n",
    "            all_items.append(item)\n",
    "    \n",
    "    item_count = Counter(all_items)\n",
    "    frequent_singletons = {}\n",
    "    \n",
    "    for item, count in item_count.items():\n",
    "        if count >= s:\n",
    "            itemset = frozenset({item})\n",
    "            frequent_singletons[itemset] = count\n",
    "    \n",
    "    return frequent_singletons\n",
    "\n",
    "\n",
    "def get_frequent_k_itemsets(previous_k_ton, transaction, support, k):\n",
    "    frequent_items = set()\n",
    "    for itemset in previous_k_ton.keys():\n",
    "        for item in itemset:\n",
    "            frequent_items.add(item)\n",
    "    \n",
    "    candidate_counts = {}\n",
    "    \n",
    "    for t in transaction:\n",
    "        relevant_items = t & frequent_items\n",
    "        \n",
    "        for pair in combinations(relevant_items, k):\n",
    "            candidate = frozenset(pair)\n",
    "            \n",
    "            if candidate in candidate_counts:\n",
    "                candidate_counts[candidate] += 1\n",
    "            else:\n",
    "                candidate_counts[candidate] = 1\n",
    "    \n",
    "    frequent_k_tons = {}\n",
    "    for candidate, count in candidate_counts.items():\n",
    "        if count >= support:\n",
    "            frequent_k_tons[candidate] = count\n",
    "    \n",
    "    return frequent_k_tons    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Assignment_2",
   "language": "python",
   "name": "mainenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
